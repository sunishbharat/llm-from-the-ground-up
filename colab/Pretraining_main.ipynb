{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_lySCnFhx43",
        "outputId": "a3c9a240-216f-45a3-80a9-aeb9301b6386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib \t: 3.10.0\n",
            "torch \t: 2.8.0+cu126\n",
            "numpy \t: 2.0.2\n",
            "tiktoken \t: 0.12.0\n",
            "tensorflow \t: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "\n",
        "pkgs = [\n",
        "    \"matplotlib\",\"torch\",\"numpy\",\"tiktoken\", \"tensorflow\"\n",
        "]\n",
        "\n",
        "[print(f\"{pkg } \\t: {version(pkg)}\") for pkg in pkgs ];"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "sys.path.append('sample_data/')\n",
        "from model_components_all import GPTModel\n"
      ],
      "metadata": {
        "id": "jPAQZ90vvdx2"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\"  : 50257,\n",
        "    \"context_len\" : 4,#256,\n",
        "    \"embd_dim\"    : 768,\n",
        "    \"num_heads\"   : 12,\n",
        "    \"num_layers\"  : 12,\n",
        "    \"dropout_rate\": 0.,\n",
        "    \"qkv_bias\"    : False,\n",
        "}\n"
      ],
      "metadata": {
        "id": "dJ3VsCBJiQl2"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "gG5fK1qOkCgT"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text to tokenids\n",
        "def text_to_tokenids(text, tokenizer):\n",
        "  tok_ids = tokenizer.encode(text)\n",
        "  token_ids = torch.tensor(tok_ids).unsqueeze(0) # add batch dim\n",
        "  return token_ids\n",
        "\n",
        "# Tokenids to text\n",
        "def tokenids_to_text(tokenids, tokenizer):\n",
        "  text = tokenizer.decode(tokenids.squeeze(0).tolist()) #remove batch dim\n",
        "  return text"
      ],
      "metadata": {
        "id": "Hypa9cdDwmoR"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Te7y1skhziI4"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"Every effort moves you\"\n",
        "tok_ids = text_to_tokenids(text1, tokenizer)\n",
        "tok_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pukFICKlzAuP",
        "outputId": "a278d2fd-2100-4b9e-c30a-37a57a90c54a"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6109, 3626, 6100,  345]])"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenids_to_text(tok_ids, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dQ-hkIqTzi3U",
        "outputId": "424f8bba-f7b7-4586-fb3a-e9b1a14c351f"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Every effort moves you'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, idx, num_samples, ctx_len):\n",
        "  for _ in range(num_samples):\n",
        "      idx_curr = idx[:,-ctx_len:]\n",
        "      with torch.no_grad():\n",
        "          logits= model(idx_curr)\n",
        "      #print(f\"{logits.shape}\")\n",
        "      idx_pred = logits[:,-1,:]\n",
        "      #Extract the position index of the largest logits\n",
        "      pred_tok = torch.argmax(idx_pred, dim=-1, keepdim=True)\n",
        "\n",
        "      #print(tokenizer.decode(idx.squeeze(0).tolist()))\n",
        "      idx= torch.cat((idx,pred_tok),dim=1)\n",
        "\n",
        "  return idx"
      ],
      "metadata": {
        "id": "zmAoVeua21zd"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = generate_text(model,tok_ids,10,4)\n",
        "print(tokenids_to_text(output,tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAfSyQt63ThI",
        "outputId": "ac66a72c-f3ae-4821-c68e-a29a53123c1e"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you naive Peerkitesley Nottingham formulationï¿½TOP IT saint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ej78SOux6LAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}