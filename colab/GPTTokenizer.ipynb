{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPTTokenizer class"
      ],
      "metadata": {
        "id": "eiGu7BtDB4OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import torch\n",
        "import urllib.request\n",
        "import re\n",
        "import tiktoken\n"
      ],
      "metadata": {
        "id": "KCSZXJ17CB-u"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 414,
      "metadata": {
        "id": "WqJxJPcdBuiM"
      },
      "outputs": [],
      "source": [
        "# GPT tokenizer class\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTTokenizer(Dataset):\n",
        "  def __init__(self,input, context_len, stride):\n",
        "    self.x = []\n",
        "    self.y = []\n",
        "\n",
        "    self.tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    tokens = self.tokenizer.encode(input)\n",
        "\n",
        "    for i in range(0, len(tokens)- context_len, stride):\n",
        "      indata = tokens[i:i+context_len]\n",
        "      target = tokens[i+1:i+context_len+1]\n",
        "      self.x.append(torch.tensor(indata))\n",
        "      self.y.append(torch.tensor(target))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]\n",
        "\n",
        "  def decode(self,tk_ids):\n",
        "    return self.tokenizer.decode([id.tolist() for id in tk_ids])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPTDataloader class"
      ],
      "metadata": {
        "id": "Uhs6ZooUB7p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_loader(input_txt, batch_size,\n",
        "                  context_len, stride, shuffle,\n",
        "                  drop_last=True, num_workers=0):\n",
        "\n",
        "  dataset = GPTTokenizer(input_txt, context_len, stride)\n",
        "\n",
        "  print(f\"{batch_size=},{context_len=}, {stride=},{shuffle=},  {num_workers=}\" )\n",
        "\n",
        "\n",
        "\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size,\n",
        "                          shuffle=shuffle,\n",
        "                          drop_last=drop_last,\n",
        "                          num_workers=num_workers)\n",
        "  return dataloader,dataset"
      ],
      "metadata": {
        "id": "CIHx4wAVB-E9"
      },
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_len = 8\n",
        "stride =8\n",
        "batch_size = 1\n",
        "\n",
        "if not os.path.exists('verdict.txt'):\n",
        "  url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "  file_path = \"sample_data/verdict.txt\"\n",
        "  urllib.request.urlretrieve(url,file_path)\n",
        "\n",
        "with open('./sample_data/verdict.txt','r',encoding='utf8') as F:\n",
        "  raw_data = F.read()\n",
        "\n",
        "dataloader,tkn = create_loader(raw_data, batch_size=batch_size,\n",
        "                                context_len=context_len,\n",
        "                                stride=stride,\n",
        "                                num_workers=0, shuffle=False)\n",
        "\n",
        "data = iter(dataloader)\n",
        "#print(len(data))\n",
        "#[(print(next(data)[0].tolist()[0])) for ii in range(1)]\n",
        "''.join([ tkn.decode(next(data)[0][0]) for ii in range(0,100,2) ])\n",
        "#tkn.decode([[40,367,2885]][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "x4NPeNXQComN",
        "outputId": "9da1d917-deef-49ad-95c9-7f13b900260e"
      },
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size=1,context_len=8, stride=8,shuffle=False,  num_workers=0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\\n\\n\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it\\'s going to send the value of my picture \\'way up; but I don\\'t think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing\\'s lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn\\'s \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?\\n\\nWell!--even through the prism of Hermia\\'s tears I felt able to face the fact with equanimity. Poor Jack Gisburn! The women had made him--it was fitting that they should mourn him. Among his own sex fewer regrets were heard, and in his own trade hardly a murmur. Professional jealousy? Perhaps. If it were, the honour of the craft was vindicated by little Claude Nutley, who, in all good faith, brought out in the Burlington a very handsome \"obituary\" on Jack--one of those showy articles stocked with random technicalities that I have heard (I won\\'t say by whom) compared to Gisburn\\'s painting. And so--his resolve being'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 416
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XdSlmE_uIDMC"
      },
      "execution_count": 416,
      "outputs": []
    }
  ]
}